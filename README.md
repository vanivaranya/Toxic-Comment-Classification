# Toxic-Comment-Classification
Dataset Information
The dataset used in this project is sourced from the Toxic Comment Classification Challenge on Kaggle conducted by cjadams, Sorensen, J., Elliott, J., Dixon, L., McDonald, M., nithum, and Cukierski in 2017.

For more details and access to the original dataset, please refer to the competition page.

Link to dataset: https://www.kaggle.com/datasets/julian3833/jigsaw-unintended-bias-in-toxicity-classification/code


In a team of 3, we classified online comments into 6 categories as toxic, severe toxic, obscene, threat, insult and identity hate, 
using a combination of Na√Øve Bayes-Linear Regression model and LSTM with an accuracy of 94.34 %.

Using this combination we achieved maximum accuracy as using these two models together
1. reduces biasedness caused by individual models
2. also reduces the effect due to overfitting by the individual models.
